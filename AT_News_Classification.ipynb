{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import konlpy\n",
    "from konlpy.tag import Twitter\n",
    "import os\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_DATA_DIR = './newsData'\n",
    "NUM_CATEGORY = 8\n",
    "BATCH_SIZE=10\n",
    "EPOCHS=12\n",
    "MIN_COUNT=2\n",
    "NUM_TEST_PER_DIRECTORY = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {}\n",
    "idx2word = {}\n",
    "num_words = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(directory):\n",
    "    print(\"%s 작업중\",%directory)\n",
    "    count = 0\n",
    "    for filename in listdir(directory):\n",
    "        if count > NUM_TEST_PER_DIRECTORY:\n",
    "            break\n",
    "        path = directory+'/'+filename\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab 만들기, 이미 정의된 vocab이 있는 경우 생략한다.\n",
    "def make_vocab():\n",
    "    if(!os.path.exists(\"/vocab.txt\"))\n",
    "        load_files(dir)\n",
    "    else \n",
    "        return load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = make_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx={}\n",
    "idx2word={}\n",
    "for i,k in enumerate(vocab):\n",
    "    word2idx[k]=i\n",
    "    idx2word[i]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_To_Index(words):\n",
    "    result=[]\n",
    "    for word in words:\n",
    "        result.append(word2idx[word])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "t_train=[]\n",
    "x_test=[]\n",
    "t_test=[]\n",
    "\n",
    "# 폴더 개수 8개\n",
    "for i in range(NUM_CATEGORY):\n",
    "    path = TEXT_DATA_DIR+'/'+str(i)\n",
    "    print(\"%s folder 작업중...\"%i)\n",
    "    count = 0\n",
    "    for filename in sorted(os.listdir(path)):\n",
    "        filename=path+'/'+filename\n",
    "        temp=Load_doc(filename)\n",
    "        temp=Clean_doc(temp,vocab)\n",
    "        temp=Word_To_Index(temp)\n",
    "        # one hot encoding\n",
    "        tempT=np.zeros(8)\n",
    "        tempT[i]=1\n",
    "        if count<160:\n",
    "            x_train.append(temp)\n",
    "            t_train.append(tempT)\n",
    "        else :\n",
    "            x_test.append(temp)\n",
    "            t_test.append(tempT)\n",
    "        count += 1\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "t_train=np.array(t_train)\n",
    "t_test=np.array(t_test)\n",
    "print(len(x_train))\n",
    "print(len(t_train))\n",
    "print(len(x_test))\n",
    "print(len(t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building Hierachical Attention Network\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,attention_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = new_parameter(attention_size,1)\n",
    "        \n",
    "    def forward(self, x_in):\n",
    "        # after this, we have (batch, dim1) with a diff weight per each cell\n",
    "        attention_score = torch.matmul(x_in, self.attention).squeeze()\n",
    "        attention_score = F.softmax(attention_score).view(x_in.size(0),x_in.size(1),1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
