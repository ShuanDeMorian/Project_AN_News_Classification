"개발 결과 예측하고 인간에 이롭도록 해야"(지디넷코리아=김우용 기자)“인공지능(AI)은 인간의 능력을 증강시키기 위해 존재하는 것이다. 그를 위해 개발자와 디자이너는 인공지능에 대해 원칙을 배워야 한다. 공정성, 프라이버시, 보안, 투명성, 포용, 책임 같은 원칙을 배우는 것이다. 소프트웨어 엔지니어링도 AI를 위한 디버깅이 필요하다.”사티아 나델라 마이크로소프트 최고경영자(CEO)는 7일 열린 ‘퓨처나우’ AI 컨퍼런스 기조연설에서 이같이 밝혔다.사티아 나델라는 “AI 기술과 업계의 사례를 보면서 기술이 나을 결과를 깊이 있게 이해해야 한다”며 “가령 언어를 훈련하는 AI는 사람의 편견도 함께 배우게 되므로, 그런 편견을 없애야 한다”고 말했다.나델라는 트랜스포메이션 테크놀로지 도입을 위해 모든 기업이 디지털로 인식을 전환해야 한다며, 프라이버시, 사이버 보안과 함께 윤리의 중요성을 강조했다.그는 “프라이버시는 이제 사람의 인권으로 생각해야 할 문제”라며 “개인의 데이터를 투명하게, 신뢰를 줄 수 있도록 보호해야 한다”고 밝혔다.사티아 나델라 마이크로소프트 CEO가 7일 열린 '퓨처나우' AI 컨퍼런스 기조연설을 하고 있다.그는 “앞으로 규제와 규정은 점점 더 강화될 것이므로, 보안과 투명성을 강구해 프라이버시를 이뤄낼 수 있도록 해야 한다”며 “보안은 일반 시민에게 가장 큰 영항을 미치는 요소이며, 인구 집단 가운데 취약 계층을 위한 보안까지 보장하려 노력해야 한다”고 덧붙였다.마이크로소프트는 지난 2016년 AI 채팅 봇 테이를 트위터로 공개했다가 히틀러를 옹호하고, 인종차별과 성적 발언 등을 연이어 내놔 하루도 안돼 서비스를 중단했다. 인터넷 데이터를 학습했던 테이는 그 과정에서 편향된 정보를 학습했다. AI가 잘못된 학습으로 엉뚱한 행동을 할 수 있다는 게 증명된 것이다.사티아 나델라 CEO는 “마이크로소프트는 내부에 윤리위원회를 두고 견고한 AI 모델을 만들도록 돕고 있다”며 “컴퓨터가 무엇을 할 수 있는지가 아니라, 무엇을 해야 하는지 물어야 할 때”라고 책임성을 강조했다.그는 “공공기관이든 사기업이든 어떻게 하면 디지털 기술을 우리 경제와 사회, 국가 전반에, 그리고 현재 경제에 활발히 참여하지 못하는 사람에게 가져다 줄 것인가 고민하라”며 “지구 환경을 위한 AI, 육아와 난민을 위한 AI 처럼 AI 접근성 프로그램을 운영하고 있으며, 연구계와 기업에서 발전시키는 다양한 기술을 모든 이에게 제공하기 위해 노력하고 있다”고 밝혔다.사티아 CEO는 이를 “최신 기술을 도입함과 동시에 각 기업 만의 고유한 경쟁력을 보유하는 것”이라며 “마이크로소프트는 기업들이 테크 인텐시티를 갖출 수 있도록 지원을 아끼지 않을 것”이라 강조했다.그는 고려대학교 이성환 교수의 뇌 신호를 기반으로 신체를 컨트롤할 수 있는 ‘로봇 팔 컨트롤(Robot Arm Control)’ 프로젝트를 소개했다. 이 프로젝트는 사람의 두뇌와 기계의 인터페이스 기술을 연구하고 있다. 뇌활동을 분석해 사람의 취지에 따라 로봇 팔을 움직일 수 있도록 하는 것이다.나델라 CEO는 “전세계 장애를 가진 사람이 10억명이지만 활발하게 경제에 참여할 기회조차 갖지 못한다”며 “이성환 교수의 연구는 장애를 가진 사람도 의지나 생각만으로 행동을 할 수 있게 하는 것으로, AI로 모든 사람이 혜택을 누리게 하는 좋은 예”라고 설명했다.그는 “마이크로소프트는 기업들이 테크 인텐시티를 갖출 수 있도록 지원을 아끼지 않을 것”이라 강조했다.이어진 기조연설에서 크레이그 샹크 마이크로소프트 정책협력법무팀 글로벌정책그룹 총괄 부사장은 “AI가 더 나은 미래를 만들기 위해서 이런 기술, 기술을 만드는 회사는 사람의 신뢰를 얻어야 한다”며 “마이크로소프트는 신뢰를 얻기 위해 인간 중심의 인공지능 접근방식을 취하기로 했다”고 말했다.그는 “AI가 인간의 기본속성을 대체하지 않고, 인간의 재능과 스킬을 보강해주도록 하려 6가지의 윤리원칙을 세웠다”며 “투명성, 책임성을 기반으로 공정성과 안전성, 프라이버시스와 보안, 포용 등의 원칙이 있다”고 설명했다.그는 “AI는 능력, 장애, 스킬 종류, 지역, 출신국가에 상관없이 사용하는 모든 사람의 경험을 받아들일 수 있어야 한다”며 “이 원칙을 통해 대화를 시작하고, 기술이 무얼 해야 하는 지 생각하기보다 기술이 해선 안되는 것을 받아들여야 하는 시점”이라고 덧붙였다