 [한겨레] 인터뷰_데이터 과학자 캐시 오닐금융위기 때 수학-금융 연계에 환멸‘월가 점거’ 참여 알고리즘 감시 나서“자동화로 더 공정해지지는 않아권력구조·개인권리침해 주시해야”데이터 과학자 캐시 오닐이 1일 오전 서울 동대문디자인플라자에서 인터뷰를 하고 있다. 박종식 기자 anaki@hani.co.kr  한국 정부는 데이터산업 활성화를 4차 산업혁명에 대응하는 주요 과제로 삼고 있다. 이 때문에 개인정보보호법 개정을 추진 중이다. ‘가명정보’의 활용 범위를 산업·상업적 목적으로 넓히려는 것이다. 가명정보 등의 ‘빅데이터’를 특정한 ‘알고리즘’으로 분석해 산업과 사회 측면에서 편익을 누릴 수 있도록 한다는 게 뼈대다. 이런 ‘알고리즘’이 민주주의를 위협한다고 주장하는 미국의 수학자·데이터 과학자가 있다. 지난해 한국에서 번역·출간된 대량살상수학무기의 저자 캐시 오닐이다. 미국 월스트리트에서 일하기도 했던 그는 금융위기를 겪으면서 수학과 금융의 연계에 환멸을 느껴 ‘월가 점거운동’에 참여하고, 알고리즘을 감시하고 위험을 측정하는 기업을 운영하고 있기도 하다. 오는 2일 열리는 ‘에스비에스(SBS) 디(D) 포럼’ 참석차 방한한 그는 1일 서울 동대문디자인플라자에서 한겨레와 만나 “알고리즘이 공정할 것이라는 생각을 버리고, 알고리즘을 민주적으로 통제해야 한다”고 강조했다.   오닐은 알고리즘 자체가 사회적 편견을 내포하고 있어 불평등을 강화할 수 있다고 말한다. 최근 미국기업 아마존이 알고리즘을 활용해 채용하면서 여성 지원자를 배제한 게 대표적 사례다. 오닐은 “우리 사회에 차별이 이미 내재해 있기 때문에 알고리즘에도 차별이 발생할 수밖에 없다. 알고리즘이 언제 제대로 작동하고, 누구에게 손해를 입히는지, 실패하는지를 기준점으로 삼아 알고리즘 사용에 대한 프레임워크를 짜야 한다”고 말했다.  오닐은 개인정보 등 데이터 활용의 ‘맥락’을 강조했다. 그는 “건강을 평가하는 지수를 기반으로 짜인 알고리즘을 의사가 갖고 있다면 언제 어떤 질병에 걸릴지 예측할 수 있고 건강을 지킬 수 있지만, 민간 의료보험사가 가지고 있다면 아플 것으로 예상되는 사람들의 보험료를 올리게 될 것”이라며 “데이터를 활용하는 맥락에 따라 사회에 편익을 줄 수도 있고, 그렇지 않을 수도 있다”고 말했다.    한국 포털사이트들은 ‘알고리즘으로 서비스를 운영한다’며 뉴스 편집 공정성 논란을 피해 가려 하지만, 오닐은 “알고리즘은 마법이 아니다”라고 강조했다. 인공지능 알고리즘을 복잡하고 논쟁적인 이슈의 ‘대안’으로 보는 시각을 경계하는 것이다. “알고리즘은 프로세스를 자동화하는 것일 뿐, 자동화한다고 해서 더 공정해지거나 더 많은 혜택이 부여되는 것이 아니다.”  오닐이 강조하는 것은 알고리즘에 대한 민주적 통제다. 그는 미국에서 인공지능 알고리즘에 기반을 둔 군사목적의 ‘킬러로봇’이나 중국에서 안면인식 기술을 활용한 범죄예방프로젝트 등에 대해서 “만약 이런 것들이 억압적 정권에서 사용된다면 질적 측면이나 정확성의 문제는 무의미해진다”며 “알고리즘 활용을 둘러싼 권력 구조에 집중해야 하고, 개인의 권리와 인권이 무시되거나 침해되는 상황을 더욱 예의주시해야 한다”고 말했다